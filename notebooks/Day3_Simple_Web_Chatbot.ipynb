{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ff7983",
   "metadata": {},
   "source": [
    "# Day 3: Simple Web Chatbot (25 minutes)\n",
    "## Build a Web Interface with Gradio\n",
    "\n",
    "Today we'll create a simple web interface for our RAG chatbot using Gradio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e342bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick setup\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_needed(package):\n",
    "    try:\n",
    "        __import__(package.split('==')[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install packages\n",
    "packages = [\"gradio\", \"sentence-transformers\", \"scikit-learn\", \"pandas\"]\n",
    "for pkg in packages:\n",
    "    install_if_needed(pkg)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbaeebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and setup (rebuild the chatbot from Day 2)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gradio as gr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data and model\n",
    "df = pd.read_csv(r\"C:\\Users\\vHaze\\Desktop\\LLMinds\\workshop2\\data\\simple_faq.csv\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "question_embeddings = model.encode(df['question'].tolist())\n",
    "\n",
    "print(f\"Loaded {len(df)} FAQs and embedding model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference vector for the word \"Hello\" to check for greetings.\n",
    "# This is done once at startup for performance, so the bot doesn't have to\n",
    "# re-calculate it for every single message. Any user input that is\n",
    "# semantically similar to this vector will be treated as a greeting.\n",
    "\n",
    "GREETING_VECTOR = model.encode([\"Hello\"])[0]\n",
    "GREETING_THRESHOLD = 0.5 \n",
    "print(\"Greeting vector created and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5bcb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chatbot function for Gradio with semantic greeting logic\n",
    "def chatbot_response(user_question, threshold=0.3):\n",
    "    if not user_question.strip():\n",
    "        return \"Please ask a question!\"\n",
    "    \n",
    "    # --- Semantic Greeting Logic Added ---\n",
    "    # Encode the user's question once for efficiency\n",
    "    query_embedding = model.encode([user_question])[0] # Get the 1D vector\n",
    "\n",
    "    # Check for greeting similarity against the pre-computed vector\n",
    "    greeting_similarity = cosine_similarity([query_embedding], [GREETING_VECTOR])[0][0]\n",
    "    \n",
    "    if greeting_similarity > GREETING_THRESHOLD:\n",
    "        return \"Hello! How can I help you today? üòä\"\n",
    "\n",
    "    # --- FAQ Search Logic (reuses the embedding) ---\n",
    "    # Find most similar FAQ using the same embedding\n",
    "    similarities = cosine_similarity([query_embedding], question_embeddings)[0] # Note: [query_embedding] makes it 2D\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    best_similarity = similarities[best_match_idx]\n",
    "    \n",
    "    # Generate response\n",
    "    if best_similarity < threshold:\n",
    "        response = \"I don't have information about that. Please contact our support team!\"\n",
    "    else:\n",
    "        response = df.iloc[best_match_idx]['answer']\n",
    "        confidence = \"High\" if best_similarity > 0.7 else \"Medium\"\n",
    "        matched_question = df.iloc[best_match_idx]['question']\n",
    "        category = df.iloc[best_match_idx]['category']\n",
    "        \n",
    "        # Add context info\n",
    "        response += f\"\\n\\nüìä **Confidence:** {confidence} ({best_similarity:.3f})\"\n",
    "        response += f\"\\nüìÇ **Category:** {category}\"\n",
    "        response += f\"\\n**üîç Matched:** {matched_question}\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test the function with a question and a greeting\n",
    "print(\"--- Testing FAQ ---\")\n",
    "print(chatbot_response(\"How can I pay for my order?\"))\n",
    "print(\"\\n--- Testing Greeting ---\")\n",
    "print(chatbot_response(\"Hey what's up\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "195bee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "def create_chatbot_interface():\n",
    "    # Create the interface\n",
    "    iface = gr.Interface(\n",
    "        fn=chatbot_response,\n",
    "        inputs=[\n",
    "            gr.Textbox(\n",
    "                label=\"Ask your question\",\n",
    "                placeholder=\"Type your question here... (e.g., 'What are your business hours?')\",\n",
    "                lines=2\n",
    "            )\n",
    "        ],\n",
    "        outputs=gr.Textbox(\n",
    "            label=\"Chatbot Response\",\n",
    "            lines=6\n",
    "        ),\n",
    "        title=\"ü§ñ Simple FAQ Chatbot\",\n",
    "        description=\"Ask questions about our services! Try asking about hours, support, payment, shipping, etc.\",\n",
    "        examples=[\n",
    "            [\"What are your business hours?\"],\n",
    "            [\"How can I contact support?\"],\n",
    "            [\"What payment methods do you accept?\"],\n",
    "            [\"How long does shipping take?\"],\n",
    "            [\"Can I return my order?\"],\n",
    "        ],\n",
    "        theme=gr.themes.Soft(),\n",
    "        allow_flagging=\"never\"\n",
    "    )\n",
    "    \n",
    "    return iface\n",
    "\n",
    "# Create the interface\n",
    "chatbot_interface = create_chatbot_interface()\n",
    "print(\"Gradio interface created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e68187a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the web interface\n",
    "print(\"Launching chatbot web interface...\")\n",
    "print(\"This will open in your browser!\")\n",
    "\n",
    "# Launch with share=True to get a public link\n",
    "chatbot_interface.launch(\n",
    "    share=True,      # Creates public link\n",
    "    server_port=7860,  # Port number\n",
    "    show_error=True    # Show errors in interface\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ Congratulations! You've built a complete RAG chatbot with web interface!\")\n",
    "print(\"\\nüìù What you've learned:\")\n",
    "print(\"- Loading and analyzing CSV data\")\n",
    "print(\"- Using Hugging Face embeddings\")\n",
    "print(\"- Building RAG (Retrieval-Augmented Generation)\")\n",
    "print(\"- Creating web interfaces with Gradio\")\n",
    "print(\"\\nüöÄ Next steps: Add more FAQs, try different models, improve the interface!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
